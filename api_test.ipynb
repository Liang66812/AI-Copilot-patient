{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import json\n",
    "\n",
    "def get_completion(prompts, model, tokenizer=None, max_tokens=512, temperature=0.8, top_p=0.95, max_model_len=2048):\n",
    "    stop_token_ids = []\n",
    "    # 创建采样参数。temperature 控制生成文本的多样性，top_p 控制核心采样的概率\n",
    "    sampling_params = SamplingParams(temperature=temperature, top_p=top_p, max_tokens=max_tokens, stop_token_ids=stop_token_ids)\n",
    "    # 初始化 vLLM 推理引擎\n",
    "    llm = LLM(model=model, tokenizer=tokenizer, max_model_len=max_model_len,trust_remote_code=True)\n",
    "    outputs = llm.generate(prompts, sampling_params)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "\n",
    "# 初始化 vLLM 推理引擎\n",
    "model='\"/data/liangyunfei/Qwen2.5-72B-Instruct-AWQ\"' # 指定模型路径\n",
    "# model=\"qwen/Qwen2-7B-Instruct\" # 指定模型名称，自动下载模型\n",
    "tokenizer = None\n",
    "# 加载分词器后传入vLLM 模型，但不是必要的。\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False) \n",
    "\n",
    "text = [\"你好，帮我介绍一下什么时大语言模型。\",\n",
    "        \"可以给我将一个有趣的童话故事吗？\"]\n",
    "\n",
    "outputs = get_completion(text, model, tokenizer=tokenizer, max_tokens=512, temperature=1, top_p=1, max_model_len=2048)\n",
    "\n",
    "# 输出是一个包含 prompt、生成文本和其他信息的 RequestOutput 对象列表。\n",
    "# 打印输出。\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel \"api_env (Python 3.10.0)\"。 \n",
      "\u001b[1;31m查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>，了解更多详细信息。 ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as DT\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from scipy.optimize import curve_fit\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel \"qwen (Python 3.10.0)\"。 \n",
      "\u001b[1;31m查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>，了解更多详细信息。 ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import uvicorn, json, datetime\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"5,6,7\"\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class Query(BaseModel):\n",
    "    text: str\n",
    "\n",
    "path = \"/workdir